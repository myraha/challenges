# Coding Challenge Evaluation Rubric

Hi there! üëã

Wistia uses a take-home coding challenge to estimate how each person performs in the areas we value in our engineers.

Specifically, we want to ensure that a candidate can:

* Implement a challenging software feature to completion.
* Code in a way that conveys their intention and logic.
* Choose appropriate approaches and design patterns.
* Use their time effectively and pragmatically.
* Communicate clearly, simply, and effectively about technical matters in writing.
* Research technical questions using widely available tools (Google, Stack Overflow, library/framework docs, etc).

The Rubric

For each question below, we ask the graders to provide their conclusion of [Strong Yes, Yes, Mixed/No, Strong No], as well as the reasoning that lead them to that conclusion.

* Implement a challenging software feature to completion.
    * Did the person implement the requested functionality to spec?
* Code in a way that conveys their intention and logic.
    * Is the code concise relative to what it does?
    * Is it clear (not just determinable) what each piece of code is doing?
    * Does the functional or object model of the code reflect the problem it is solving?
* Choose appropriate approaches and design patterns.
    * Are the difficulties that the candidate identifies commensurate with the level of the position they're applying for?
    * Based on this project, does this candidate seem to skew junior, senior, or somewhere in the middle?
* Use their time effectively.
    * Are the areas in which the candidate spent the most time important to the project? Or did they get distracted around the edges?
* Communicate clearly in prose.
    * Provided the instructions, was it easy to run the project and observe its behavior?
    * Is the written prose (i.e. README, comments) clear, and does it use as simple language as possible (but no simpler)[1] to describe its content?
* Write proficiently about technical matters.
    * Where comments are used, are they effective in conveying an intention beyond what the code itself conveys?
    * Does the candidate accurately and usefully describe the concepts behind their implementation?
* Research basic technical questions as one would during their daily work.

[1] https://quoteinvestigator.com/2011/05/13/einstein-simple/

We offer some additional guidance to our engineers who are grading these projects. In the interest of transparency, and so that you can turn in your best work, here is what we tell them:

* Use fact-based analysis. Make sure your conclusions derive from evidence in the face of a stated expectation, not from an assumption of what someone was thinking or attempting to do. An ideal analysis is clear about what was expected, what was provided, and what if any conclusions you drew from the difference between them.
* Stick to the rubric. If you have a thought that's beyond our rubric, and you are confident it's important, please record it in the ‚ÄúOutside our Rubric‚Äù section and state why you feel it's important and relevant. This helps us reduce bias by acknowledging the topic as off-rubric. It also gives us a chance to reflect on whether it _should_ be part of our rubric moving forward.
* Maintain categorical independence. Don't try to force a singular conclusion about an assignment. It is normal for a candidate to be great at one thing and need work in another.
* Be fair, but don't make excuses. Hold candidates to the same standard you'd hold your teammates. We expect candidates to put their best foot forward when looking for a job; if they don't, we have no way to assess whether they would do so on the job.
* If you have doubts that are quickly and easily disprovable, reach out to the candidate and attempt to do so. Ask very clear and straightforward questions when a short answer can disprove a doubt. For instance, if a project is mostly on point but you're asked to run a terminal command that produces a syntax error, it's reasonable to email the candidate and ask what shell they were using to run that command.
